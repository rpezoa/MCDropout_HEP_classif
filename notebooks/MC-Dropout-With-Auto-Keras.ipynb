{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9ae58b",
   "metadata": {},
   "source": [
    "# Uncertainty estimation in deep learning based-classifiers of High Energy Physics events using Monte Carlo Dropout.\n",
    "-----\n",
    "## Higgs Dataset\n",
    "\n",
    "R. Pezoa (UV, CCTVal-USM), S. BÃ³rquez(USM), W. Brooks (USM), L. Salinas (USM), C. Torres (USM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cdd23",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e48651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import autokeras as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,  Input\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mc_dropout import *\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e04b94-8e0a-43b5-80d9-4e2053936574",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b018d",
   "metadata": {},
   "source": [
    "## Data\n",
    "-----\n",
    "Hggs dataset\n",
    "\n",
    "- Data is obtained from: https://www.openml.org/d/23512\n",
    "- Each event is represented by a set of 28 features, including 21 low-level features corresponding to physics properties measured by the detector, and 7 high-level features derived from the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8fb86-eea7-4c78-b511-8b6ed0a6f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/storage-large/dataset/higgs/phpZLgL9q.csv\"\n",
    "#data_path = \"/mnt/storage-large/dataset/higgs/HIGGS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08133da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_=420\n",
    "# Read data file\n",
    "df = pd.read_csv(data_path)\n",
    "df.rename(columns = {'class': 'label'}, inplace = True)\n",
    "# Removing last row containinng \"?\" values\n",
    "df.drop(df.tail(1).index,inplace=True) # drop last n rows\n",
    "df = df.apply(pd.to_numeric)\n",
    "# Pandas dataframe for correlation matrix without label column\n",
    "df_corr = df.drop('label', inplace=False, axis=1)\n",
    "\n",
    "# Scaling data\n",
    "y = df[\"label\"]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=X.columns)\n",
    "\n",
    "# Features names\n",
    "features_names = list(X.columns)\n",
    "\n",
    "# Training, validation, and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=seed_)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle = True, test_size=0.2, random_state=seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e53c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# X_train: %s\" % (X_train.shape[0]))\n",
    "print(\"# X_val: %s\" % (X_val.shape[0]))\n",
    "print(\"# X_test: %s\" % (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d68812",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.astype(float)\n",
    "y_test = y_test.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec995ea-bf70-43ac-b859-cfb9a9ece8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e56042-6c8c-4094-a4d2-7a5b1d64f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697f415",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ab493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier(max_depth=15)\n",
    "#start_time = time.time()\n",
    "#rf.fit(X_train, y_train)\n",
    "#elapsed_time = time.time() - start_time\n",
    "#print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "#accuracy_score(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f967e-165b-4b0a-b9ee-927b883efb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func = FunctionTransformer(np.expm1)\n",
    "#X_exp = np.hstack((X,func.fit_transform(X)))\n",
    "\n",
    "#poly = PolynomialFeatures(2)\n",
    "#X_poly = poly.fit_transform(X_exp)\n",
    "#X_poly = poly.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "# Training, validation, and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=seed_)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle = True, test_size=0.2, random_state=seed_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10d158-5f95-4b80-820a-eb9657f562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d55de",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "--- \n",
    "We will use AutoKeras\n",
    "\n",
    "https://autokeras.com/tutorial/structured_data_classification/\n",
    "\n",
    "https://autokeras.com/structured_data_classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f107e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 1 #20\n",
    "max_trials =  1 #2000 # tries n different models.\n",
    "metrics = ['accuracy',  tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50649507-e593-49b1-8600-19f5df37f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine import hyperparameters\n",
    "\n",
    "\n",
    "class DensePReLUBlock(ak.DenseBlock):\n",
    "    def build(self, hp, inputs=None):\n",
    "        inputs = tf.nest.flatten(inputs)\n",
    "        ak.utils.utils.validate_num_inputs(inputs, 1)\n",
    "        input_node = inputs[0]\n",
    "        output_node = input_node\n",
    "        output_node = ak.blocks.reduction.Flatten().build(hp, output_node)\n",
    "\n",
    "        use_batchnorm = self.use_batchnorm\n",
    "        if use_batchnorm is None:\n",
    "            use_batchnorm = hp.Boolean(\"use_batchnorm\", default=False)\n",
    "\n",
    "        for i in range(ak.utils.utils.add_to_hp(self.num_layers, hp)):\n",
    "            units = ak.utils.utils.add_to_hp(self.num_units, hp, \"units_{i}\".format(i=i))\n",
    "            output_node = tf.keras.layers.Dense(units)(output_node)\n",
    "            if use_batchnorm:\n",
    "                output_node = tf.keras.layers.BatchNormalization()(output_node)\n",
    "            output_node = tf.keras.layers.PReLU(output_node)  # I changed this activation function only\n",
    "            if ak.utils.utils.add_to_hp(self.dropout, hp) > 0:\n",
    "                output_node = tf.keras.layers.Dropout(ak.utils.utils.add_to_hp(self.dropout, hp))(\n",
    "                    output_node\n",
    "                )\n",
    "        return output_node\n",
    "\n",
    "\n",
    "def get_automodel(max_trials, num_classes, metrics, column_names, overwrite, objective):    \n",
    "    input_node = ak.StructuredDataInput(column_names=column_names)\n",
    "    #output_node = DensePReLUBlock(\n",
    "    output_node = ak.DenseBlock(\n",
    "        num_layers=hyperparameters.Choice(\"num_layers\", [3, 4,  5, 6], default=3),\n",
    "        num_units=hyperparameters.Choice(\"num_units\", [32, 64, 128, 256, 512], default=128)\n",
    "    )(input_node)\n",
    "    output_node = ak.ClassificationHead(num_classes=num_classes, metrics=metrics)(output_node)\n",
    "    auto_model = ak.AutoModel(\n",
    "        inputs=input_node, outputs=output_node, overwrite=overwrite, max_trials=max_trials, objective=objective\n",
    "    )\n",
    "    return auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f0607-c0a5-462a-91cd-fb09751e7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the structured data classifier.\n",
    "auto_model = get_automodel(\n",
    "    max_trials=max_trials,\n",
    "    column_names=features_names,\n",
    "    num_classes=num_classes,\n",
    "    metrics=metrics,\n",
    "    objective='val_accuracy',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c9c20-2812-4a09-8972-1c3d912f63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the structured data classifier with training data.\n",
    "h = auto_model.fit(\n",
    "    x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=epochs, verbose=2#, #callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f8ec8-c8fc-4afc-94dd-1e2da73811b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model.evaluate(X_val, y_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab136cb-b59a-48e3-aedd-b831ba55af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model.evaluate(X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c03a2-50c4-4676-8be4-457b0174c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_model.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8198b-9ce0-4a8b-9311-a2608c1f3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92265902-92fc-4ac0-8711-0e2fca908a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ba2e7-c75e-48dc-9d2c-7453a52c93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = get_mc_model(model, metrics)\n",
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec302d-e1e4-461d-9559-53052f29a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(mc_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b0718-6ba1-406f-a333-820cccabb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.save('mc_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903cfc8",
   "metadata": {},
   "source": [
    "## Traditional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e5072-ffb5-4a01-8a48-a00afd742a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc489011",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848eadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(h.history['accuracy'])\n",
    "#plt.plot(h.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c16f5",
   "metadata": {},
   "source": [
    "## Bayesian Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d50974-0184-4f3c-96d3-4fd14cea4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = tf.keras.models.load_model('mc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mc = mc_model.fit(X_train, y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(h_mc.history['loss'], label=\"train loss\")\n",
    "plt.plot(h_mc.history['val_loss'], label=\"val loss\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(h_mc.history['accuracy'], label = \"train acc\")\n",
    "plt.plot(h_mc.history['val_accuracy'], label = \"val acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1982edce",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81295fe2-7cee-46cf-8bbf-fd9c0b4bee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd42618",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_predictions = np.array(\n",
    "    [\n",
    "    mc_model.predict_on_batch(X_test)\n",
    "    for i in tqdm.tqdm(range(T))\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f410887",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_predictions.shape  # (T, batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12c997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "for y_p in mc_predictions:\n",
    "    # Select predicted class\n",
    "    y_p_class = proba_to_class(y_p)\n",
    "    acc = accuracy_score(y_test, y_p_class)\n",
    "    prec = precision_score(y_test, y_p_class)\n",
    "    rec = recall_score(y_test, y_p_class)\n",
    "    f1 = f1_score(y_test, y_p_class)\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recs.append(rec)\n",
    "    f1s.append(f1)\n",
    "print(\"MC accuracy: {:.1%}\".format(sum(accs)/len(accs)))\n",
    "print(\"MC precision: {:.1%}\".format(sum(precs)/len(precs)))\n",
    "print(\"MC recall: {:.1%}\".format(sum(recs)/len(recs)))\n",
    "print(\"MC f1: {:.1%}\".format(sum(f1s)/len(f1s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18559b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ensemble_pred = predictive_distribution(mc_predictions)\n",
    "\n",
    "mc_ensemble_pred_class = proba_to_class(mc_ensemble_pred)\n",
    "\n",
    "\n",
    "ensemble_acc = accuracy_score(y_test, mc_ensemble_pred_class)\n",
    "ensemble_f1 = f1_score(y_test, mc_ensemble_pred_class)\n",
    "print(\"MC-ensemble accuracy: {:.1%}\".format(ensemble_acc))\n",
    "print(\"MC-ensemble f1-score: {:.1%}\".format(ensemble_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.hist(accs);\n",
    "plt.axvline(x=ensemble_acc, color=\"b\");\n",
    "plt.title(\"accuracy distribution on testing data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00358fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.hist(f1s);\n",
    "plt.title(\"F1 distribution on testing data\") \n",
    "plt.axvline(x=ensemble_f1, color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d923e",
   "metadata": {},
   "source": [
    "## Some tests on specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0 # taking data with index idx\n",
    "# mc_predictions, a list with 500 elements, because we have 500 forward passes:\n",
    "# each element is a numpy array of size (n_tests, 2)\n",
    "\n",
    "# this line is taking the test data with idx=1 of each forward pass, and putting it into p0\n",
    "p0 = mc_predictions[:, idx]\n",
    "p0_predictive_distribution = predictive_distribution(p0)\n",
    "\n",
    "# these are examples of highly uncertain prediction\n",
    "#p0 = np.random.uniform(0, 1, (500,1))\n",
    "#p0_predictive_distribution = predictive_distribution(p0)\n",
    "\n",
    "#p0 = np.where(np.random.uniform(0, 1, (500,1)) > 0.5, 1, 0)\n",
    "#p0_predictive_distribution = predictive_distribution(p0)\n",
    "\n",
    "# this is a example of low uncertain prediction\n",
    "#p0 = np.zeros((500,1))\n",
    "#p0_predictive_distribution = predictive_distribution(p0)\n",
    "\n",
    "# mean of the prediction in data with idx=1\n",
    "print(\"predictive distribution: {:.2%}\".format(p0_predictive_distribution))\n",
    "print(\"posterior mean: {}\".format(p0_predictive_distribution > 0.5))\n",
    "print(\"true label: {}\".format(int(np.array(y_test)[idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0f415",
   "metadata": {},
   "source": [
    "## Computing variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bf9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"class: {}; proba: {:.2%}; var: {:.2%} \".format(0, (1 - p0).mean(), (1-p0).std()))\n",
    "print(\"class: {}; proba: {:.2%}; var: {:.2%} \".format(1, p0.mean(), p0.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9369971-6156-4fc1-9011-0d75ff152e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.hist(p0, bins=20);\n",
    "plt.title(\"Samples distribution on a test instance\") \n",
    "plt.axvline(x=p0_predictive_distribution, color=\"b\", label='Predictive distribution');\n",
    "plt.legend()\n",
    "plt.xlabel('$p(y|x,w_t)$')\n",
    "plt.xlim([0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86fb33",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Computing mutual information\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62ac5e-6ad9-4483-b313-babbb050913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information(mc_ensemble_pred, mc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f6521-9b9c-4642-9eec-c54d44b86047",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information(p0_predictive_distribution, p0, is_sample=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a22d9",
   "metadata": {},
   "source": [
    "## Computing predictive entropy\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202c480-b98d-4064-b738-eb1627070e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_entropy(mc_ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d6bcf-6802-4336-86d2-cf7ad69a8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_entropy(p0_predictive_distribution, is_sample=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15900732-2356-45dd-aa91-f4c945be9175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3aecf5715e11a78c2618bdb2316cc3cb85e68efb4ce3d948bdd007a3315b4a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
